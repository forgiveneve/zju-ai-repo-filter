
import streamlit as st
import requests
import pandas as pd
import time

st.set_page_config(page_title="GitHub AI é¡¹ç›®ç­›é€‰å™¨", layout="wide")
st.title("ğŸ” GitHub AI åè®­ç»ƒé¡¹ç›®ç­›é€‰å™¨")
st.markdown("é€šè¿‡å…³é”®è¯æŒ–æ˜ä¼˜è´¨ AI å¾®è°ƒé¡¹ç›®å€™é€‰äºº")

keywords_input = st.text_input("å…³é”®è¯ï¼ˆè‹±æ–‡é€—å·åˆ†éš”ï¼‰", "LoRA,SFT,RLHF")
min_stars = st.slider("æœ€å° Stars", 0, 500, 5)
created_after = st.date_input("åˆ›å»ºæ—¶é—´å¤§äº", pd.to_datetime("2023-01-01"))
max_repos = st.slider("æœ€å¤šç»“æœæ•°", 10, 200, 50)
github_token = st.text_input("GitHub Tokenï¼ˆå¿…å¡«ï¼‰", type="password")

def search_github_repos(keyword, page, headers, min_stars, created_after):
    url = "https://api.github.com/search/repositories"
    query = f"{keyword} language:Python stars:>={min_stars} created:>={created_after}"
    params = {
        "q": query,
        "sort": "stars",
        "order": "desc",
        "per_page": 30,
        "page": page
    }
    response = requests.get(url, headers=headers, params=params)
    if response.status_code == 200:
        return response.json()
    else:
        return {}

def get_user_info(username, headers):
    url = f"https://api.github.com/users/{username}"
    res = requests.get(url, headers=headers)
    if res.status_code == 200:
        user = res.json()
        return user.get("email"), user.get("bio")
    return None, None

if st.button("å¼€å§‹ç­›é€‰"):
    if not github_token:
        st.error("è¯·è¾“å…¥ GitHub Tokenã€‚")
    else:
        headers = {"Authorization": f"token {github_token}"}
        all_results = []
        created_str = created_after.strftime("%Y-%m-%d")
        with st.spinner("æ­£åœ¨æŠ“å– GitHub æ•°æ®..."):
            for keyword in [k.strip() for k in keywords_input.split(",") if k.strip()]:
                for page in range(1, 4):
                    data = search_github_repos(keyword, page, headers, min_stars, created_str)
                    items = data.get("items", [])
                    if not items:
                        break
                    for item in items:
                        username = item["owner"]["login"]
                        email, bio = get_user_info(username, headers)
                        all_results.append({
                            "é¡¹ç›®åç§°": item["name"],
                            "æè¿°": item["description"],
                            "Stars": item["stargazers_count"],
                            "é“¾æ¥": item["html_url"],
                            "ä½œè€…": username,
                            "é‚®ç®±": email,
                            "Bio": bio,
                            "æ˜¯å¦å¯èƒ½æ¥è‡ªZJU": "Zhejiang" in (bio or "") or "ZJU" in (bio or ""),
                            "æ˜¯å¦ZJUé‚®ç®±": email.endswith("zju.edu.cn") if email else False
                        })
                        if len(all_results) >= max_repos:
                            break
                    time.sleep(1)
                if len(all_results) >= max_repos:
                    break
        df = pd.DataFrame(all_results)
        st.success(f"å…±è·å– {len(df)} ä¸ªé¡¹ç›®")
        st.dataframe(df)
        csv = df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button("ğŸ“¥ ä¸‹è½½CSVæ–‡ä»¶", csv, "github_ai_candidates.csv", "text/csv")
